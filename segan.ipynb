{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5057a37e44cffd2c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from urllib import request\n",
    "import zipfile\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "from progress_bar import ProgressBar "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.182940Z",
     "start_time": "2024-04-18T22:50:26.498376Z"
    }
   },
   "id": "4eb87b5b2ca9eac0",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defentions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1f3e9904725e5c3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.198725Z",
     "start_time": "2024-04-18T22:50:29.184491Z"
    }
   },
   "id": "84406c52beab97c0",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca0d95b0f3646ff0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1611eea56ae30598"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataIndex:\n",
    "    url: str\n",
    "    id: str\n",
    "\n",
    "    @property\n",
    "    def dir(self):\n",
    "        return self.url.split('/')[-1].split('.')[0]\n",
    "\n",
    "    def list_files(self, data_dir: str):\n",
    "        return sorted([os.path.join(data_dir, self.dir, f) for f in os.listdir(os.path.join(data_dir, self.dir)) if\n",
    "                       f.endswith('.wav')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.214078Z",
     "start_time": "2024-04-18T22:50:29.199764Z"
    }
   },
   "id": "d0467463b78725e6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class XyDataIndexPair:\n",
    "    X_data_index: DataIndex\n",
    "    y_data_index: DataIndex\n",
    "    stage: str\n",
    "\n",
    "    def list_file_pairs(self, data_dir: str):\n",
    "        X_files = self.X_data_index.list_files(data_dir)\n",
    "        y_files = self.y_data_index.list_files(data_dir)\n",
    "        file_pair_lst = list(zip(X_files, y_files))\n",
    "        for X_file, y_file in file_pair_lst:\n",
    "            assert os.path.basename(X_file) == os.path.basename(y_file), f'X: {X_file} != y: {y_file}'\n",
    "        return file_pair_lst"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.229107Z",
     "start_time": "2024-04-18T22:50:29.215110Z"
    }
   },
   "id": "1e452c4674ef2f2e",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b413cf0a44ec9e92"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AudioDataset(IterableDataset):\n",
    "    def __init__(self, Xy_data_index_pair: XyDataIndexPair, data_dir=data_dir, window_size=16384,\n",
    "                 window_size_overlap_percentage=0.5, target_sample_rate=16000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            directory (string): Directory with all the audio files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.Xy_data_index_pair = Xy_data_index_pair\n",
    "        self.Xy_file_pairs = Xy_data_index_pair.list_file_pairs(data_dir)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.window_size = window_size\n",
    "        self.window_overlap = int(window_size_overlap_percentage * window_size)\n",
    "\n",
    "    def _read_audio(self, file):\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "        assert sample_rate == self.target_sample_rate, f'Expected sample rate of {self.target_sample_rate} but got {sample_rate} for file {file}'\n",
    "        return waveform.squeeze(0), sample_rate\n",
    "\n",
    "    def __iter__(self):\n",
    "        for X_file, y_file in self.Xy_file_pairs:\n",
    "            X_waveform, X_sample_rate = self._read_audio(X_file)\n",
    "            y_waveform, y_sample_rate = self._read_audio(y_file)\n",
    "            assert X_waveform.shape[-1] == y_waveform.shape[\n",
    "                -1], f'Expected same number of samples but got {X_waveform.shape[-1]} and {y_waveform.shape[-1]} for files {X_file} and {y_file}'\n",
    "            for i in range(0, X_waveform.shape[-1], self.window_size - self.window_overlap):\n",
    "                X_waveform_window = X_waveform[..., i:i + self.window_size]\n",
    "                y_waveform_window = y_waveform[..., i:i + self.window_size]\n",
    "                yield X_waveform_window, y_waveform_window"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.244673Z",
     "start_time": "2024-04-18T22:50:29.230625Z"
    }
   },
   "id": "3312cc0f1ad00224",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26d4a65a4e54991d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=data_dir, sample_rate=16000):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.bitstream_prefix = 'http://datashare.is.ed.ac.uk/bitstream/handle/10283/1942'\n",
    "\n",
    "        self.Xy_data_index_lst = [\n",
    "            XyDataIndexPair(\n",
    "                X_data_index=DataIndex(url=f'{self.bitstream_prefix}/noisy_trainset_wav.zip', id='noisy'),\n",
    "                y_data_index=DataIndex(url=f'{self.bitstream_prefix}/clean_trainset_wav.zip', id='clean'),\n",
    "                stage='train',\n",
    "            ),\n",
    "            XyDataIndexPair(\n",
    "                X_data_index=DataIndex(url=f'{self.bitstream_prefix}/noisy_testset_wav.zip', id='noisy'),\n",
    "                y_data_index=DataIndex(url=f'{self.bitstream_prefix}/clean_testset_wav.zip', id='clean'),\n",
    "                stage='val',\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        '''\n",
    "        Download and extract data\n",
    "        '''\n",
    "        for Xy_data_index_pair in tqdm(self.Xy_data_index_lst):\n",
    "            for data_index in [Xy_data_index_pair.X_data_index, Xy_data_index_pair.y_data_index]:\n",
    "                self.download_and_extract(data_index.url, os.path.join(self.data_dir, data_index.dir))\n",
    "                self.convert_wavs(os.path.join(self.data_dir, data_index.dir),\n",
    "                                  os.path.join(self.data_dir, data_index.dir))\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        '''\n",
    "        Create train, val, test datasets and dataloaders\n",
    "        :param stage: in fit, test, predict\n",
    "        :return: None\n",
    "        '''\n",
    "        find_index_pair_by_stage = lambda stage: \\\n",
    "            [index_pair for index_pair in self.Xy_data_index_lst if index_pair.stage == stage][0]\n",
    "\n",
    "        valid_index_pair = find_index_pair_by_stage('val')\n",
    "        valid_dataset = AudioDataset(valid_index_pair, data_dir=self.data_dir,\n",
    "                                     target_sample_rate=self.sample_rate, window_size_overlap_percentage=0.0)\n",
    "\n",
    "        if stage == 'fit' or stage is None:\n",
    "            train_index_pair = find_index_pair_by_stage('train')\n",
    "            self.train_dataset = AudioDataset(train_index_pair, data_dir=self.data_dir,\n",
    "                                              target_sample_rate=self.sample_rate, window_size_overlap_percentage=0.5)\n",
    "            self.valid_dataset = valid_dataset\n",
    "        if stage == 'test' or stage == 'predict':\n",
    "            self.predict_dataset = valid_dataset\n",
    "            self.test_dataset = valid_dataset\n",
    "\n",
    "    def download_and_extract(self, url, extract_to):\n",
    "        zip_path = f'{extract_to}.zip'\n",
    "        if not os.path.exists(zip_path):\n",
    "            print(f'DOWNLOADING DATASET FROM {url}...')\n",
    "            zip_dir = os.path.dirname(zip_path)\n",
    "            if not os.path.exists(zip_dir):\n",
    "                os.makedirs(zip_dir)\n",
    "            request.urlretrieve(url, zip_path, ProgressBar())\n",
    "        if not os.path.exists(extract_to):\n",
    "            print(f'INFLATING ZIP FROM {zip_path} TO {extract_to} ...')\n",
    "            os.makedirs(extract_to)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "\n",
    "    def convert_wavs(self, source_dir, target_dir):\n",
    "        print(f'CONVERTING WAVS FROM {source_dir} TO {target_dir}')\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir)\n",
    "            for wav_file in os.listdir(source_dir):\n",
    "                if wav_file.endswith('.wav'):\n",
    "                    source_path = os.path.join(source_dir, wav_file)\n",
    "                    target_path = os.path.join(target_dir, wav_file)\n",
    "                    subprocess.run(['sox', source_path, '-r', self.sample_rate, target_path], check=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=400, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset, batch_size=400, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=400, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.259774Z",
     "start_time": "2024-04-18T22:50:29.245704Z"
    }
   },
   "id": "8f78ee15cdde1b5b",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create datamodule inst"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3417394d7c6c2d9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datamodule = AudioDataModule(data_dir=data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.275208Z",
     "start_time": "2024-04-18T22:50:29.260773Z"
    }
   },
   "id": "3d9119b93005cf24",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2003.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERTING WAVS FROM data\\noisy_trainset_wav TO data\\noisy_trainset_wav\n",
      "CONVERTING WAVS FROM data\\clean_trainset_wav TO data\\clean_trainset_wav\n",
      "CONVERTING WAVS FROM data\\noisy_testset_wav TO data\\noisy_testset_wav\n",
      "CONVERTING WAVS FROM data\\clean_testset_wav TO data\\clean_testset_wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datamodule.prepare_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.290753Z",
     "start_time": "2024-04-18T22:50:29.276719Z"
    }
   },
   "id": "a5d7e0bc11c4a90f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datamodule.setup(stage='fit')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.429955Z",
     "start_time": "2024-04-18T22:50:29.291754Z"
    }
   },
   "id": "42770941f9c92195",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X,y = next(iter(datamodule.train_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.445483Z",
     "start_time": "2024-04-18T22:50:29.430964Z"
    }
   },
   "id": "fc7d6ca216230f22",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([16384]), torch.Size([16384]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:39.985210Z",
     "start_time": "2024-04-18T22:50:39.979208Z"
    }
   },
   "id": "603aeba845a92e11",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T22:50:29.476099Z",
     "start_time": "2024-04-18T22:50:29.461362Z"
    }
   },
   "id": "1d9112c8dde2fc21",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
